import torch
from torch import nn
import math
import torch.nn.functional as F
from .util import Smooth, EqualizedLinear
from .util import SinusoidalPositionEmbeddings
import numpy as np


class Discriminator(nn.Module):
    """
        Diffusion timestep conditioned discriminator
        following principles in Diffusion-GAN paper with
        ddded Sinusoidal positional embedding
    """

    def __init__(self,
                 log_resolution: int,
                 n_features: int = 64,
                 max_features: int = 512,
                 embedding_dim=64):
        super().__init__()

        # Layer to convert RGB image to a feature map with `n_features` number of features.
        self.from_rgb = nn.Sequential(
            EqualizedConv2d(3, n_features, 1),
            nn.LeakyReLU(0.2, True),
        )

        # Calculate the number of features for each block.
        #
        # Something like `[64, 128, 256, 512, 512, 512]`.
        features = [
            min(max_features, n_features * (2**i))
            for i in range(log_resolution - 1)
        ]
        # Number of [discirminator blocks](#discriminator_block)
        n_blocks = len(features) - 1
        # Discriminator blocks
        blocks = [
            DiscriminatorBlock(features[i], features[i + 1])
            for i in range(n_blocks)
        ]
        self.blocks = nn.Sequential(*blocks)

        # [Mini-batch Standard Deviation](#mini_batch_std_dev)
        self.std_dev = MiniBatchStdDev()
        # Number of features after adding the standard deviations map
        final_features = features[-1] + 1
        self.final_features = final_features
        # Final $3 \times 3$ convolution layer
        self.conv = EqualizedConv2d(final_features, final_features, 3)
        # Final linear layer to get the classification
        self.act = nn.LeakyReLU(0.2, True)
        self.prefinal = EqualizedLinear(2 * 2 * final_features, final_features)
        self.final = EqualizedLinear(final_features, 1)
        #self.class_embed = nn.Embedding(num_classes, final_features)
        self.time_mlp = nn.Sequential(
            SinusoidalPositionEmbeddings(embedding_dim),
            nn.Linear(embedding_dim, final_features),
            nn.GELU(),
            nn.Linear(final_features, final_features),
        )

    def forward(self, x: torch.Tensor, t, labels=None):
        # Try to normalize the image (this is totally optional, but sped up the early training a little)
        #x = x - 0.5 # this could be detrimental
        # Convert from RGB
        x = self.from_rgb(x)
        # Run through the [discriminator blocks](#discriminator_block)
        x = self.blocks(x)

        # Calculate and append [mini-batch standard deviation](#mini_batch_std_dev)
        x = self.std_dev(x)
        # $3 \times 3$ convolution
        x = self.conv(x)
        # Flatten
        x = x.reshape(x.shape[0], -1)
        # Return the classification score
        x = self.prefinal(x)
        x = self.act(x)
        #out = self.final(features)
        t_embedding = self.time_mlp(t)
        #class_embedding = self.class_embed(labels)
        x = (x * t_embedding).sum(
            dim=1, keepdim=True) * (1 / np.sqrt(self.final_features))
        #proj = (features * t_embedding).sum(dim=1, keepdim=True) + (features * class_embedding).sum(dim=1, keepdim=True)
        #return proj + out
        return x


class DiscriminatorBlock(nn.Module):

    def __init__(self, in_features, out_features):
        super().__init__()
        # Down-sampling and $1 \times 1$ convolution layer for the residual connection
        self.residual = nn.Sequential(
            DownSample(),
            EqualizedConv2d(in_features, out_features, kernel_size=1))

        # Two $3 \times 3$ convolutions
        self.block = nn.Sequential(
            EqualizedConv2d(in_features, in_features, kernel_size=3,
                            padding=1),
            nn.LeakyReLU(0.2, True),
            EqualizedConv2d(in_features,
                            out_features,
                            kernel_size=3,
                            padding=1),
            nn.LeakyReLU(0.2, True),
        )

        # Down-sampling layer
        self.down_sample = DownSample()

        self.scale = 1 / math.sqrt(2)

    def forward(self, x):
        # Get the residual connection
        residual = self.residual(x)

        # Convolutions
        x = self.block(x)
        # Down-sample
        x = self.down_sample(x)

        # Add the residual and scale
        return (x + residual) * self.scale


class DownSample(nn.Module):

    def __init__(self):
        super().__init__()
        # Smoothing layer
        self.smooth = Smooth()

    def forward(self, x: torch.Tensor):
        # Smoothing or blurring
        x = self.smooth(x)
        # Scaled down
        return F.interpolate(x, (x.shape[2] // 2, x.shape[3] // 2),
                             mode='bilinear',
                             align_corners=False)


class MiniBatchStdDev(nn.Module):

    def __init__(self, group_size: int = 4):
        super().__init__()
        self.group_size = group_size

    def forward(self, x: torch.Tensor):
        # Check if the batch size is divisible by the group size
        assert x.shape[0] % self.group_size == 0
        # Split the samples into groups of `group_size`, we flatten the feature map to a single dimension
        # since we want to calculate the standard deviation for each feature.
        grouped = x.view(self.group_size, -1)
        # Calculate the standard deviation for each feature among `group_size` samples

        std = torch.sqrt(grouped.var(dim=0) + 1e-8)
        # Get the mean standard deviation
        std = std.mean().view(1, 1, 1, 1)
        # Expand the standard deviation to append to the feature map
        b, _, h, w = x.shape
        std = std.expand(b, -1, h, w)
        # Append (concatenate) the standard deviations to the feature map
        return torch.cat([x, std], dim=1)


class EqualizedConv2d(nn.Module):

    def __init__(self,
                 in_features: int,
                 out_features: int,
                 kernel_size: int,
                 padding: int = 0):
        super().__init__()
        # Padding size
        self.padding = padding
        # [Learning-rate equalized weights](#equalized_weights)
        #self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])
        self.weight = nn.Parameter(
            torch.randn(out_features, in_features, kernel_size, kernel_size))

        fan_in = in_features * kernel_size * kernel_size
        self.scale = 1 / math.sqrt(fan_in)
        # Bias
        self.bias = nn.Parameter(torch.ones(out_features))

    def forward(self, x: torch.Tensor):
        # Convolution
        scaled_weight = self.weight * self.scale
        return F.conv2d(x, scaled_weight, bias=self.bias, padding=self.padding)
